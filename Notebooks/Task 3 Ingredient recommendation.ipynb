{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91748d70-fe9b-41d7-8def-febf5b284994",
   "metadata": {},
   "source": [
    "# SNLP project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa1cab-f3e4-4361-8eba-fd10c277077f",
   "metadata": {},
   "source": [
    "## Ingredient recommendation task \n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Produce some suggestions for substitution for certain ingredients, e,g, “vegan” and “pesto pasta” might give us “tofu”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7bb3f5-c9e5-4952-9142-f378e41c9a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sannalun/opt/anaconda3/envs/spoonacular/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02451eb1-88c6-42fe-b254-803de5cecf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaneddata.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf468396-a8ba-4c45-899a-fd395178f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa3dfb-6b04-4cde-8206-08df7f4e24e3",
   "metadata": {},
   "source": [
    "## 1. Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f993f00-d851-477c-b636-fbdda5c3b8b7",
   "metadata": {},
   "source": [
    "### 1.1 Drop column we don't need and renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb3597d-e788-465f-b5d6-d4086c3ef605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"healthScore\", \"pricePerServing\", \"readyInMinutes\", \"servings\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16dc70f4-c3bd-4f4f-ad6f-100fa5ca7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"glutenFree\": \"gluten-free\", \n",
    "    \"dairyFree\": \"dairy-free\", \n",
    "    \"veryHealthy\":\"very-healthy\", \n",
    "    \"veryPopular\": \"very-popular\", \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c557f-44fa-4909-b892-229e6284b699",
   "metadata": {},
   "source": [
    "### 1.2 Transform the TRUE classification labels to class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91d9e6b-a984-4a64-87ad-fc9c3601a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['vegetarian', \n",
    "           'vegan', \n",
    "           'gluten-free', \n",
    "           'dairy-free', \n",
    "           'very-healthy', \n",
    "           'cheap', \n",
    "           'very-popular', \n",
    "           'sustainable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1119c718-42af-40af-847a-0d92a9bf1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    df[c] = df[c].replace(to_replace=[True, False], value=[c, np.nan])\n",
    "# df = df.drop([\"instructions\", \"summary\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921bd1ff-833f-43b1-94fd-c44ffca26993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient types</th>\n",
       "      <th>diets</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>vegan</th>\n",
       "      <th>gluten-free</th>\n",
       "      <th>dairy-free</th>\n",
       "      <th>very-healthy</th>\n",
       "      <th>cheap</th>\n",
       "      <th>very-popular</th>\n",
       "      <th>sustainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>orange fig teacake with caramel glaze is a veg...</td>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>ap flour; baking powder; cardamom; eggs; fresh...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>bread; butter; eggs; eggs; mushrooms; oil; sal...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>for 26 cents per serving   this recipe covers ...</td>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>all purpose flour; bay leaves; coconut milk; c...</td>\n",
       "      <td>Ethnic Foods Produce Spices and Seasonings Bev...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dairy-free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>pork chop with honey  mustard and apples might...</td>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>apples; dijon mustard; garlic cloves; honey; j...</td>\n",
       "      <td>Meat Spices and Seasonings Condiments Oil Vine...</td>\n",
       "      <td>gluten free; dairy free; paleolithic; primal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten-free</td>\n",
       "      <td>dairy-free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>the recipe beet gnocchi with steak and brown b...</td>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>gnocchi; beets; olive oil; s p; goat cheese; r...</td>\n",
       "      <td>Produce Spices and Seasonings Meat Spices and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0              orange fig teacake with caramel glaze   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2                                pandan chiffon cake   \n",
       "3           pork chop with honey  mustard and apples   \n",
       "4     beet gnocchi with steak and brown butter sauce   \n",
       "\n",
       "                                             summary  \\\n",
       "0  orange fig teacake with caramel glaze is a veg...   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2  for 26 cents per serving   this recipe covers ...   \n",
       "3  pork chop with honey  mustard and apples might...   \n",
       "4  the recipe beet gnocchi with steak and brown b...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0   you will need a 9  springform pan  or a cake ...   \n",
       "1   in a frying pan heat up oil then add mushroom...   \n",
       "2   preheat the oven to 170c  blend the pandan le...   \n",
       "3   pre heat your oven to 200c   400f  line a roa...   \n",
       "4  cooking beets heat oven to 400 degrees wash be...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ap flour; baking powder; cardamom; eggs; fresh...   \n",
       "1  bread; butter; eggs; eggs; mushrooms; oil; sal...   \n",
       "2  all purpose flour; bay leaves; coconut milk; c...   \n",
       "3  apples; dijon mustard; garlic cloves; honey; j...   \n",
       "4  gnocchi; beets; olive oil; s p; goat cheese; r...   \n",
       "\n",
       "                                    ingredient types  \\\n",
       "0  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "1  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "2  Ethnic Foods Produce Spices and Seasonings Bev...   \n",
       "3  Meat Spices and Seasonings Condiments Oil Vine...   \n",
       "4  Produce Spices and Seasonings Meat Spices and ...   \n",
       "\n",
       "                                          diets  vegetarian vegan  \\\n",
       "0                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "1                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "2              dairy free; lacto ovo vegetarian  vegetarian   NaN   \n",
       "3  gluten free; dairy free; paleolithic; primal         NaN   NaN   \n",
       "4                                           NaN         NaN   NaN   \n",
       "\n",
       "   gluten-free  dairy-free very-healthy cheap very-popular  sustainable  \n",
       "0          NaN         NaN          NaN   NaN          NaN          NaN  \n",
       "1          NaN         NaN          NaN   NaN          NaN          NaN  \n",
       "2          NaN  dairy-free          NaN   NaN          NaN          NaN  \n",
       "3  gluten-free  dairy-free          NaN   NaN          NaN          NaN  \n",
       "4          NaN         NaN          NaN   NaN          NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd104963-10c1-4695-9e89-2f035b909ed6",
   "metadata": {},
   "source": [
    "### 1.3 Creating two copies of the diets and ingredients columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfd3d4-3275-461f-88bc-633afc447625",
   "metadata": {},
   "source": [
    "The ingredients and diets are going to be important for this tasks. To make our model more flexible, we will expand the vocabularies in these categories. \n",
    "\n",
    "For diets, we want to include both `\"gluten free\"` and `\"gluten-free\"` in the corpus. For ingredients, we want to include both `\"extra virgin olive oil\"` and `\"extra\", \"virgin\", \"olive\", \"oil\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3080ccc9-b8df-463b-a8a2-089a6dcc6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"ingredient split\"] = df[\"ingredients\"].str.replace(\"; \", \" \")\n",
    "df[\"diet-split\"] = df[\"diets\"].str.replace(\" \", \"-\").str.replace(\";-\", \"; \")\n",
    "modify_cols = [\"gluten-free\", \"dairy-free\", \"very-healthy\", \"very-popular\"]\n",
    "for col in modify_cols:\n",
    "    i = df.columns.get_loc(col)\n",
    "    df.iloc[:, i] = df.iloc[:, i] + \"; \" + df.iloc[:, i].str.replace(\"-\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26baea6d-1647-435b-876b-940dae2a4b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient types</th>\n",
       "      <th>diets</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>vegan</th>\n",
       "      <th>gluten-free</th>\n",
       "      <th>dairy-free</th>\n",
       "      <th>very-healthy</th>\n",
       "      <th>cheap</th>\n",
       "      <th>very-popular</th>\n",
       "      <th>sustainable</th>\n",
       "      <th>diet-split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>orange fig teacake with caramel glaze is a veg...</td>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>ap flour; baking powder; cardamom; eggs; fresh...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lacto-ovo-vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>bread; butter; eggs; eggs; mushrooms; oil; sal...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lacto-ovo-vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>for 26 cents per serving   this recipe covers ...</td>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>all purpose flour; bay leaves; coconut milk; c...</td>\n",
       "      <td>Ethnic Foods Produce Spices and Seasonings Bev...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dairy-free; dairy free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dairy-free; lacto-ovo-vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>pork chop with honey  mustard and apples might...</td>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>apples; dijon mustard; garlic cloves; honey; j...</td>\n",
       "      <td>Meat Spices and Seasonings Condiments Oil Vine...</td>\n",
       "      <td>gluten free; dairy free; paleolithic; primal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten-free; gluten free</td>\n",
       "      <td>dairy-free; dairy free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gluten-free; dairy-free; paleolithic; primal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>the recipe beet gnocchi with steak and brown b...</td>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>gnocchi; beets; olive oil; s p; goat cheese; r...</td>\n",
       "      <td>Produce Spices and Seasonings Meat Spices and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0              orange fig teacake with caramel glaze   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2                                pandan chiffon cake   \n",
       "3           pork chop with honey  mustard and apples   \n",
       "4     beet gnocchi with steak and brown butter sauce   \n",
       "\n",
       "                                             summary  \\\n",
       "0  orange fig teacake with caramel glaze is a veg...   \n",
       "1  poached eggs on a bed of fried mushrooms and c...   \n",
       "2  for 26 cents per serving   this recipe covers ...   \n",
       "3  pork chop with honey  mustard and apples might...   \n",
       "4  the recipe beet gnocchi with steak and brown b...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0   you will need a 9  springform pan  or a cake ...   \n",
       "1   in a frying pan heat up oil then add mushroom...   \n",
       "2   preheat the oven to 170c  blend the pandan le...   \n",
       "3   pre heat your oven to 200c   400f  line a roa...   \n",
       "4  cooking beets heat oven to 400 degrees wash be...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ap flour; baking powder; cardamom; eggs; fresh...   \n",
       "1  bread; butter; eggs; eggs; mushrooms; oil; sal...   \n",
       "2  all purpose flour; bay leaves; coconut milk; c...   \n",
       "3  apples; dijon mustard; garlic cloves; honey; j...   \n",
       "4  gnocchi; beets; olive oil; s p; goat cheese; r...   \n",
       "\n",
       "                                    ingredient types  \\\n",
       "0  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "1  Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "2  Ethnic Foods Produce Spices and Seasonings Bev...   \n",
       "3  Meat Spices and Seasonings Condiments Oil Vine...   \n",
       "4  Produce Spices and Seasonings Meat Spices and ...   \n",
       "\n",
       "                                          diets  vegetarian vegan  \\\n",
       "0                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "1                          lacto ovo vegetarian  vegetarian   NaN   \n",
       "2              dairy free; lacto ovo vegetarian  vegetarian   NaN   \n",
       "3  gluten free; dairy free; paleolithic; primal         NaN   NaN   \n",
       "4                                           NaN         NaN   NaN   \n",
       "\n",
       "                gluten-free              dairy-free very-healthy cheap  \\\n",
       "0                       NaN                     NaN          NaN   NaN   \n",
       "1                       NaN                     NaN          NaN   NaN   \n",
       "2                       NaN  dairy-free; dairy free          NaN   NaN   \n",
       "3  gluten-free; gluten free  dairy-free; dairy free          NaN   NaN   \n",
       "4                       NaN                     NaN          NaN   NaN   \n",
       "\n",
       "  very-popular  sustainable                                    diet-split  \n",
       "0          NaN          NaN                          lacto-ovo-vegetarian  \n",
       "1          NaN          NaN                          lacto-ovo-vegetarian  \n",
       "2          NaN          NaN              dairy-free; lacto-ovo-vegetarian  \n",
       "3          NaN          NaN  gluten-free; dairy-free; paleolithic; primal  \n",
       "4          NaN          NaN                                           NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665952df-55f5-4bb3-b143-73eda5c981de",
   "metadata": {},
   "source": [
    "## 2. Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5fdaa8-b8dd-4501-a4bf-18cd4168f949",
   "metadata": {},
   "source": [
    "Here I use the Gensim library to create a word2vec embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4fa68-e06f-4e1e-a091-3743a19a06e3",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- Gensim Word2Vec documentation: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "- DAS, P, 2020. How to train word2vec model using gensim library [online]. Medium. [viewed 26/03/2020]. Available from: https://medium.com/swlh/how-to-train-word2vec-model-using-gensim-library-115b35440c90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7547c-cc85-445d-8ae1-0c4a4f96fbdb",
   "metadata": {},
   "source": [
    "#### 2.1 Trainsform data into the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874034ff-ce4b-414b-be9a-c690e580e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainWord2Vec = False\n",
    "word2vec_path = \"../Word2Vec/word2vec.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64924373-0feb-4197-bfd7-a6465846a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sannalun/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "if trainWord2Vec:\n",
    "    download('stopwords')\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2844f0e-98bc-4be5-8b1f-cd3fd076da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence(object):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.n_rows = df.shape[0]\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        # these columns are strings with values separated by ;\n",
    "        self.semi_colon_cols = [\"ingredients\", \"diets\", \"diet-split\", \"gluten-free\", \n",
    "                                \"dairy-free\", \"very-healthy\", \"very-popular\"]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for n in range(self.n_rows):\n",
    "            row = self.df.iloc[n]\n",
    "            sentence : List[str] = []\n",
    "            for i, cell in enumerate(row):\n",
    "                if type(cell) == str:\n",
    "                    sent = cell.split(\"; \") if df.columns[i] in self.semi_colon_cols else cell.split()\n",
    "                    sent = [w.lower() for w in sent if w not in stop_words]\n",
    "                    if len(sent) > 0: sent[-1] = self.lemmatizer.lemmatize(sent[-1])\n",
    "                    sentence += sent\n",
    "            yield sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1c9e88-af48-47fa-a155-ae1806673432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiase\n",
    "if trainWord2Vec:\n",
    "    sentences = Sentence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb17bc-b056-4dad-be8f-e031da95d769",
   "metadata": {},
   "source": [
    "### 2.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a70df-7059-42e4-b4ee-7570abf6b22e",
   "metadata": {},
   "source": [
    "After experimenting with different values, the following setup seem to give reasonable results:\n",
    "- vector size 300\n",
    "- min count 1\n",
    "- window 5\n",
    "- epoch 30\n",
    "\n",
    "Training time: ~80 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad47dae4-43ff-4eaa-8d7f-191314cbbd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 84.1069917678833s.\n"
     ]
    }
   ],
   "source": [
    "if trainWord2Vec:\n",
    "    start = time.time()\n",
    "    model = Word2Vec(sentences, min_count=1, vector_size=300, \n",
    "                     workers=2, window=2, epochs=30, sg=0)\n",
    "    end = time.time()\n",
    "    model.save(word2vec_path)\n",
    "    print(f\"Training comleted in {end-start}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88226908-c113-45cd-b1ba-950eacb2ce90",
   "metadata": {},
   "source": [
    "### 2.3 Generate ingredient suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06d08e-45df-4b61-abd2-10696d9abf2f",
   "metadata": {},
   "source": [
    "To get ingredient suggestions, we will provide the desired postiive (and maybe also negetive) keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddec5d15-d27a-4414-a53c-380a5550ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(word2vec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45730190-b56d-4874-afb6-981ef09a2b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feta',\n",
       " 'fresh mozzarella cheese',\n",
       " 'dressing',\n",
       " 'gluten-free',\n",
       " 'pescatarian',\n",
       " 'rigate',\n",
       " 'primal',\n",
       " 'lasagna',\n",
       " 'gluten free',\n",
       " 'gorgonzola']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = w2v_model.wv.most_similar(positive=[\"vegan\", \"pesto\", \"pasta\"], topn=10)\n",
    "results = [res[0] for res in results]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79848c90-d366-427f-aae2-66f081eed701",
   "metadata": {},
   "source": [
    "The results are satisfactory. For example, even though \"feta\" and \"fresh mozzarella cheese\" are not vegan, they are somewhat resonable suggestions. There are at least no meat on the list. \n",
    "\n",
    "However, we also observed that there are a lot of non-ingredient words in the list of suggestions, such as \"free\". Therefore, we decided to find out to exclude suggestions that are not in the list of ingredients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc650b-90ab-4cb5-8b5f-938312d103fc",
   "metadata": {},
   "source": [
    "### 2.4 Improved ingredient suggestion generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60540c5-39d7-4f50-9004-f5b18009146c",
   "metadata": {},
   "source": [
    "Our strategy is:\n",
    "1. Obtain a list of candicate incredients, save it in a list\n",
    "2. Generate suggestions like above, but filter out suggestions that are not in the ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216b86c5-c08e-4620-b49a-e64bbb3110de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = df[\"ingredients\"].to_list()\n",
    "# ingredients_split = df[\"ingredient split\"].to_list()\n",
    "\n",
    "all_ingredients = []\n",
    "for i in ingredients: \n",
    "    items = i.split(\"; \")\n",
    "    all_ingredients += items\n",
    "\n",
    "# for i in ingredients_split: \n",
    "#     items = i.split()\n",
    "#     all_ingredients += items\n",
    "\n",
    "all_ingredients = list(set(all_ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a56a512-16ad-454e-a5b5-32ae8c89eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients(ingredients: List[str], \n",
    "                    recipe: List[str], \n",
    "                    positive: List[str], \n",
    "                    negative: List[str] = [], \n",
    "                    topn=20):\n",
    "    \n",
    "    pos = recipe.split() + positive*3\n",
    "    candidates = model.wv.most_similar(positive=pos, negative=negative*2, topn=200)\n",
    "    \n",
    "    substitutions = []\n",
    "    for ingredient_name, _ in candidates:\n",
    "        if len(substitutions) >= topn:\n",
    "            break\n",
    "        if ingredient_name in ingredients:\n",
    "            substitutions.append(ingredient_name)\n",
    "    return substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a32d9fa-294c-4add-b20a-8dbe1c3e9353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feta',\n",
       " 'fresh mozzarella cheese',\n",
       " 'mushroom',\n",
       " 'gorgonzola',\n",
       " 'honey',\n",
       " 'cherry',\n",
       " 'bread',\n",
       " 'arugula',\n",
       " 'seasoning blend',\n",
       " 'bulgur',\n",
       " 'crepes',\n",
       " 'mayo',\n",
       " 'buckwheat',\n",
       " 'ricotta',\n",
       " 'nutella']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ingredients(all_ingredients, \n",
    "                recipe=\"pesto pasta\", \n",
    "                positive=[\"vegan\"], \n",
    "                negative=[], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa56ba4-23db-4087-9632-27a65b1d368f",
   "metadata": {},
   "source": [
    "## 3. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cfa87-3c4b-4b34-ba6b-5c1739307a86",
   "metadata": {},
   "source": [
    "### 3.1 Using pretrained Bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1afe1b7-9fc3-4b31-a873-76bffbefbbd8",
   "metadata": {},
   "source": [
    "There are a lot of powerful pretrained BERT models and we would like to see whether the expressive power of BERT would help it success this task better than Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ded2cf2-532a-4bcb-bd37-18de23858a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40c9be43-e362-4861-bc75-278f5d76dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fill_pretrained = pipeline(\"fill-mask\", \n",
    "                model=\"bert-base-uncased\", \n",
    "                tokenizer=\"bert-base-uncased\", \n",
    "                top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ddbe49-4c4a-4dd1-a396-b7a844f1b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', '&', 'salad', 'with', '-', ',', 'fried', ':', 'or', 'chicken']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = fill_pretrained.tokenizer.mask_token\n",
    "results = fill_pretrained(f\"vegan pesto {mask} pasta\")\n",
    "results = [r['token_str'] for r in results]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31dfe0-6f33-491d-b3fc-ff6bd9ae82b4",
   "metadata": {},
   "source": [
    "The results are not very satisfactory as none of the outputs seem to capture our requirements. The first ingredient output is chicken which is clearly not vegan and not even vegetarian. We would therefore like to explore whether custom trained BERT would perform better in this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb3aa7-1f50-45dd-9e8b-ed116730c109",
   "metadata": {},
   "source": [
    "### 3.2 Custom - RoBerta model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd0bc3-a63c-46c4-9045-e4d75ac2e781",
   "metadata": {},
   "source": [
    "There are multiple BERT-like models out there. We have chosen to train a RoBerta model, whose implementation is essentially the same with a few tweaks. In particular, it removes the next-sentence pretraining objective, and focus on the masked language modelling objective. This makes us believe that this is more suitable as we believe that the latter objective is more relevant to the task at hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e93980-c159-45b2-b71e-8892eb7fad26",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- Roberta documentation [online]. Hugging Face. [viewed 30/03/2020]. Available from:. https://huggingface.co/docs/transformers/model_doc/roberta\n",
    "- Briggs, J., How to Train a BERT Model From Scratch [online]. Medium. [viewed 30/30/2020]. Available from: https://towardsdatascience.com/how-to-train-a-bert-model-from-scratch-72cfce554fc6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d867fd9-afab-460a-bd6c-40c83779db2c",
   "metadata": {},
   "source": [
    "Training time: 6 hours 18 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb729d4-7fa3-4012-ac87-cb1d43b1d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train to True to train model \n",
    "trainBert = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb3bb07-0df6-4b71-a465-fbf8685b902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizerFast, RobertaConfig, RobertaForMaskedLM, AdamW\n",
    "import os \n",
    "from tqdm.auto import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da15b191-bff1-41a0-9cd0-cd65b7394396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"../BERT/recipe_tokenizer\"\n",
    "bert_model_path = \"../BERT/model\"\n",
    "bert_recipe_path = \"../BERT/recipes.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e53d3-5aaa-49bf-a977-f0831fe4a169",
   "metadata": {},
   "source": [
    "#### Create the text file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75ddeafe-7c1d-437a-90a4-622cc78ed6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    df1 = df.apply(lambda x: \" \".join([cell for cell in x if type(cell)==str]), axis=1)\n",
    "\n",
    "    recipes = \"\\n\".join(df1.to_list())\n",
    "    with open(bert_recipe_path, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8caf09-0fd1-467f-90fd-15b5fbd60070",
   "metadata": {},
   "source": [
    "#### Train tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52b98534-5313-42e0-9c51-a2724c114586",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    \n",
    "    # Train the tokenizer with text\n",
    "    tokenizer.train(files=[bert_recipe_path], \n",
    "                vocab_size=30_522, \n",
    "                min_frequency=1, \n",
    "                special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n",
    "    os.mkdir(tokenizer_path)\n",
    "    tokenizer.save_model(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ae3ccde-d9fe-424e-9239-83b15a8517ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4c5ef71-a6c3-4318-9fe0-72a9bce096b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../BERT/recipe_tokenizer/tokenizer_config.json',\n",
       " '../BERT/recipe_tokenizer/special_tokens_map.json',\n",
       " '../BERT/recipe_tokenizer/vocab.json',\n",
       " '../BERT/recipe_tokenizer/merges.txt',\n",
       " '../BERT/recipe_tokenizer/added_tokens.json',\n",
       " '../BERT/recipe_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8af892ef-4914-4318-9c60-f41b7dbedebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 8327, 974, 2], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"pesto pasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3a36b-349f-432b-b57c-18ed517244c0",
   "metadata": {},
   "source": [
    "### Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "911c9b60-d15c-4e24-a443-51d34c6f3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm(tensor):\n",
    "    \"\"\"\n",
    "    input: tensor of sentences\n",
    "    output: tensor of sentences with masks words\n",
    "    \"\"\"\n",
    "    rand = torch.rand(tensor.shape)\n",
    "    mask_arr = (rand < 0.15) * (tensor > 2)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        tensor[i, selection] = 4 # mask token\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a34bfb4d-adb3-48f2-a46c-eaa86ea99908",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    input_ids = []\n",
    "    attn_mask = [] \n",
    "    labels = []\n",
    "\n",
    "    with open(bert_recipe_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    sample = tokenizer(lines, \n",
    "                       max_length=512, \n",
    "                       padding=\"max_length\", \n",
    "                       truncation=True, \n",
    "                       return_tensors='pt')\n",
    "    labels.append(sample.input_ids)\n",
    "    attn_mask.append(sample.attention_mask)\n",
    "    input_ids.append(mlm(sample.input_ids.detach().clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "405f1c94-ae78-401a-a14b-f9590267575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd34017a-ac81-42ad-b571-e2e3ae92a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    # set up for training\n",
    "    input_ids = torch.cat(input_ids)\n",
    "    attn_mask = torch.cat(attn_mask)\n",
    "    labels = torch.cat(labels)\n",
    "    \n",
    "    encodings = {\n",
    "    'input_ids': input_ids,\n",
    "    'attention_mask': attn_mask,\n",
    "    'labels': labels\n",
    "    }\n",
    "    \n",
    "    dataset = Dataset(encodings)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    config = RobertaConfig(\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    max_position_embeddings=514, \n",
    "    hidden_size = 768, \n",
    "    num_attention_heads=12, \n",
    "    num_hidden_layers= 6, \n",
    "    type_vocab_size = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f6f2902-5046-4239-a590-407210c07201",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = AdamW(model.parameters(), lr=1e-4)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "730a63d5-6550-4a8d-b5cc-ed571a4a3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainBert:\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch: {epochs}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    model.save_pretrained(bert_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d76d02-3c5b-4322-b544-6e94ae304706",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed95105d-3180-4c61-934c-f411b6b96109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../BERT/model were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../BERT/model and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(bert_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dce7419-22d4-449c-9795-fdf7428682ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' and', ';', ' the', ' to', ' a', ' with', '<pad>', ' of', '  ']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill = pipeline(\"fill-mask\", model=bert_model_path, tokenizer=tokenizer_path, top_k=10)\n",
    "\n",
    "results = fill(f\"vegan pesto {fill.tokenizer.mask_token} pasta\")\n",
    "results = [c['token_str'] for c in results]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73601dee-12a1-4a82-91e3-b4c0443c2934",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dabb729-38e5-46d7-8d1e-70724c41b3a3",
   "metadata": {},
   "source": [
    "1. Came up with 13 random recipe requirements. \n",
    "2. Generate prediction with all three models\n",
    "3. Evaluate by two evaluators, score 0...5\n",
    "4. Calculate the average score for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0ba9752-893a-4a61-bddd-6933f1ece8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Custom Word2Vec\n",
    "w2v_model = Word2Vec.load(word2vec_path)\n",
    "\n",
    "# Pretrained BERT\n",
    "bert_pretrained = fill_pretrained = pipeline(\n",
    "    \"fill-mask\", \n",
    "    model=\"bert-base-uncased\", \n",
    "    tokenizer=\"bert-base-uncased\",\n",
    "    top_k=10)\n",
    "\n",
    "# Custom BERT\n",
    "tokenizer_path = \"../BERT/recipe_tokenizer\"\n",
    "bert_model_path = \"../BERT/model\"\n",
    "bert_recipe_path = \"../BERT/recipes.txt\"\n",
    "bert_custom = pipeline(\n",
    "    \"fill-mask\", \n",
    "    model=bert_model_path, \n",
    "    tokenizer=tokenizer_path, \n",
    "    top_k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2d3f2-dc62-42bc-b477-4c7107b96acc",
   "metadata": {},
   "source": [
    "#### 4.1 Came up with 13 random recipe requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c8821f2-c9ee-42f4-a3e5-3d38143ac591",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test = [\n",
    "    \"budget vegan curry rice\", \n",
    "    \"vegan soup\",\n",
    "    \"quick one pot pasta\", \n",
    "    \"vegetarian fried rice\", \n",
    "    \"asian soup noodles\", \n",
    "    \"quick and easy fried noodles\",\n",
    "    \"quick vegan pasta\",\n",
    "    \"cheap dairy-free soup\", \n",
    "    \"gluten-free cheesecake\", \n",
    "    \"quick vegetarian salad with mozzarella\", \n",
    "    \"vegetarian creamy pasta\", \n",
    "    \"cheap vegetarian pasta\", \n",
    "    \"gluten-free tomato pasta\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a7e887e-90d9-438e-bed1-8f70d3facbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_test_set(mask):\n",
    "    bert_test = [\n",
    "        f\"budget vegan curry {mask} rice\", \n",
    "        f\"vegan {mask} soup\",\n",
    "        f\"quick one pot {mask} pasta\", \n",
    "        f\"vegetarian {mask} fried rice\", \n",
    "        f\"asian {mask} soup noodles\", \n",
    "        f\"quick and easy {mask} fried noodles\",\n",
    "        f\"quick vegan {mask} pasta\",\n",
    "        f\"cheap dairy-free {mask} soup\", \n",
    "        f\"gluten-free {mask} cheesecake\", \n",
    "        f\"quick vegetarian {mask} salad with mozzarella\", \n",
    "        f\"vegetarian creamy {mask} pasta\", \n",
    "        f\"cheap vegetarian {mask} pasta\", \n",
    "        f\"gluten-free tomato {mask} pasta\"\n",
    "        ]\n",
    "    return bert_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb91ae6-6edf-4b09-8d8a-1f467c3fd692",
   "metadata": {},
   "source": [
    "#### 4.2 Generate prediction with all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61dff657-a1cf-4fb9-85b5-a535f3d492a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_recommendations = {}\n",
    "for recipe in w2v_test:\n",
    "    words = recipe.split()\n",
    "    words = [word for word in words if w2v_model.wv.has_index_for(word)]\n",
    "    results = w2v_model.wv.most_similar(words, topn=10)\n",
    "    results = [r[0] for r in results]\n",
    "    w2v_recommendations[recipe] = results\n",
    "df = pd.DataFrame(w2v_recommendations)\n",
    "df.to_csv(\"Task3_evaluations/w2v_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf88db83-b149-4ef7-8402-74ad7a35b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pretrained_test = generate_bert_test_set(bert_pretrained.tokenizer.mask_token)\n",
    "bert_pretrained_recommendations = {}\n",
    "for recipe in bert_pretrained_test:\n",
    "    results = bert_pretrained(recipe)\n",
    "    results = [res['token_str'] for res in results]\n",
    "    bert_pretrained_recommendations[recipe] = results\n",
    "\n",
    "df = pd.DataFrame(bert_pretrained_recommendations)\n",
    "df.to_csv(\"Task3_evaluations/bert_pretrained_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "152f8307-e830-4ba1-a87c-9337b97a4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_custom_test = generate_bert_test_set(bert_custom.tokenizer.mask_token)\n",
    "bert_custom_recommendations = {}\n",
    "for recipe in bert_custom_test:\n",
    "    results = bert_custom(recipe)\n",
    "    results = [res['token_str'] for res in results]\n",
    "    bert_custom_recommendations[recipe] = results\n",
    "    \n",
    "df = pd.DataFrame(bert_custom_recommendations)\n",
    "df.to_csv(\"Task3_evaluations/bert_custom_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecef1d5-83e0-4c61-97d0-0e5346c6f465",
   "metadata": {},
   "source": [
    "#### Calculate the average score for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eabfa9a8-1f38-4a86-8744-23b9edf422d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ccae70e4-eeeb-4ce6-977b-725b32e4c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_evaluation_files = glob.glob(\"Task3_evaluations/w2v_evaluation_*.csv\")\n",
    "dfs = map(lambda path: pd.read_csv(path, index_col=0, sep=\";\"), w2v_evaluation_files)\n",
    "w2v_evaluations = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "be642be0-68ab-4bd0-8476-20a56783d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bert_eval_files = glob.glob(\"Task3_evaluations/bert_pretrained_evaluation_*.csv\")\n",
    "dfs = map(lambda path: pd.read_csv(path, index_col=0, sep=\";\"), pretrained_bert_eval_files)\n",
    "pretrained_bert_eval = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c4c3625-e97e-4617-b1b7-a1548e9ed2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bert_eval_files = glob.glob(\"Task3_evaluations/bert_custom_evaluation*.csv\")\n",
    "dfs = map(lambda path: pd.read_csv(path, index_col=0, sep=\";\"), custom_bert_eval_files)\n",
    "custom_bert_eval = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d516f540-9cb6-4f91-af7c-fecf3e1dd0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2038461538461538"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_bert_eval.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "14cf62e8-a1b6-49df-a719-bf0e393950e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5923076923076924"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_evaluations.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f23f57f6-4202-4889-9afc-682009d69c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_bert_eval.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce6fa-fab9-47b3-879a-f4ebd6dc117d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
