{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d0a851",
   "metadata": {},
   "source": [
    "## 1. A LOOK IN THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0afbadb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\sarab\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4752e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ps=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import time \n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "data=pd.read_csv('C:/Users/sarab/Downloads/cleaneddata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "715a65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4e47f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient types</th>\n",
       "      <th>diets</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>vegan</th>\n",
       "      <th>glutenFree</th>\n",
       "      <th>dairyFree</th>\n",
       "      <th>veryHealthy</th>\n",
       "      <th>cheap</th>\n",
       "      <th>veryPopular</th>\n",
       "      <th>sustainable</th>\n",
       "      <th>healthScore</th>\n",
       "      <th>pricePerServing</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>orange fig teacake with caramel glaze is a veg...</td>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>ap flour; baking powder; cardamom; eggs; fresh...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.55</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>bread; butter; eggs; eggs; mushrooms; oil; sal...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>147.70</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>for 26 cents per serving   this recipe covers ...</td>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>all purpose flour; bay leaves; coconut milk; c...</td>\n",
       "      <td>Ethnic Foods Produce Spices and Seasonings Bev...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.06</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>pork chop with honey  mustard and apples might...</td>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>apples; dijon mustard; garlic cloves; honey; j...</td>\n",
       "      <td>Meat Spices and Seasonings Condiments Oil Vine...</td>\n",
       "      <td>gluten free; dairy free; paleolithic; primal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17.0</td>\n",
       "      <td>242.23</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>the recipe beet gnocchi with steak and brown b...</td>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>gnocchi; beets; olive oil; s p; goat cheese; r...</td>\n",
       "      <td>Produce Spices and Seasonings Meat Spices and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>417.69</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>yakitori glaze</td>\n",
       "      <td>yakitori glaze might be just the japanese reci...</td>\n",
       "      <td>combine all ingredients in a small saucepan a...</td>\n",
       "      <td>butter; egg yolks; flour; orange zest; poppy s...</td>\n",
       "      <td>Milk Eggs Other Dairy Spices and Seasonings Ba...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.70</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>instructions collard greens using a non stick ...</td>\n",
       "      <td>unbaked pie crust; shredded cheddar cheese; ja...</td>\n",
       "      <td>Milk Eggs Other Dairy Meat Spices and Seasonin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>63.0</td>\n",
       "      <td>493.63</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>white chocolate cheesecake with raspberries</td>\n",
       "      <td>the recipe white chocolate cheesecake with ras...</td>\n",
       "      <td>to make the crumb crust in a small bowl combin...</td>\n",
       "      <td>egg yolks; grand marnier; light brown sugar; o...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Alcoholic Beve...</td>\n",
       "      <td>gluten free; lacto ovo vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>139.70</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>fish pie with fresh and smoked salmon</td>\n",
       "      <td>this recipe makes 2 servings with 710 calories...</td>\n",
       "      <td>peel potatoes and cut into chunks cook in boi...</td>\n",
       "      <td>cashew; cumin; eggplant; flour; garam masala; ...</td>\n",
       "      <td>Beverages Spices and Seasonings Canned and Jar...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian; vegan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1013.56</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>mushroom  bacon  pull apart bread</td>\n",
       "      <td>the recipe mushroom  bacon  pull apart bread c...</td>\n",
       "      <td>lay the yeast rolls out on the counter until t...</td>\n",
       "      <td>puff pastry; brie; dried figs; apple juice; su...</td>\n",
       "      <td>Beverages Baking Dried Fruits Produce Cheese P...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.13</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4305 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                 orange fig teacake with caramel glaze   \n",
       "1     poached eggs on a bed of fried mushrooms and c...   \n",
       "2                                   pandan chiffon cake   \n",
       "3              pork chop with honey  mustard and apples   \n",
       "4        beet gnocchi with steak and brown butter sauce   \n",
       "...                                                 ...   \n",
       "4300                                     yakitori glaze   \n",
       "4301  pan seared honey glazed salmon with collard gr...   \n",
       "4302        white chocolate cheesecake with raspberries   \n",
       "4303              fish pie with fresh and smoked salmon   \n",
       "4304                  mushroom  bacon  pull apart bread   \n",
       "\n",
       "                                                summary  \\\n",
       "0     orange fig teacake with caramel glaze is a veg...   \n",
       "1     poached eggs on a bed of fried mushrooms and c...   \n",
       "2     for 26 cents per serving   this recipe covers ...   \n",
       "3     pork chop with honey  mustard and apples might...   \n",
       "4     the recipe beet gnocchi with steak and brown b...   \n",
       "...                                                 ...   \n",
       "4300  yakitori glaze might be just the japanese reci...   \n",
       "4301  pan seared honey glazed salmon with collard gr...   \n",
       "4302  the recipe white chocolate cheesecake with ras...   \n",
       "4303  this recipe makes 2 servings with 710 calories...   \n",
       "4304  the recipe mushroom  bacon  pull apart bread c...   \n",
       "\n",
       "                                           instructions  \\\n",
       "0      you will need a 9  springform pan  or a cake ...   \n",
       "1      in a frying pan heat up oil then add mushroom...   \n",
       "2      preheat the oven to 170c  blend the pandan le...   \n",
       "3      pre heat your oven to 200c   400f  line a roa...   \n",
       "4     cooking beets heat oven to 400 degrees wash be...   \n",
       "...                                                 ...   \n",
       "4300   combine all ingredients in a small saucepan a...   \n",
       "4301  instructions collard greens using a non stick ...   \n",
       "4302  to make the crumb crust in a small bowl combin...   \n",
       "4303   peel potatoes and cut into chunks cook in boi...   \n",
       "4304  lay the yeast rolls out on the counter until t...   \n",
       "\n",
       "                                            ingredients  \\\n",
       "0     ap flour; baking powder; cardamom; eggs; fresh...   \n",
       "1     bread; butter; eggs; eggs; mushrooms; oil; sal...   \n",
       "2     all purpose flour; bay leaves; coconut milk; c...   \n",
       "3     apples; dijon mustard; garlic cloves; honey; j...   \n",
       "4     gnocchi; beets; olive oil; s p; goat cheese; r...   \n",
       "...                                                 ...   \n",
       "4300  butter; egg yolks; flour; orange zest; poppy s...   \n",
       "4301  unbaked pie crust; shredded cheddar cheese; ja...   \n",
       "4302  egg yolks; grand marnier; light brown sugar; o...   \n",
       "4303  cashew; cumin; eggplant; flour; garam masala; ...   \n",
       "4304  puff pastry; brie; dried figs; apple juice; su...   \n",
       "\n",
       "                                       ingredient types  \\\n",
       "0     Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "1     Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "2     Ethnic Foods Produce Spices and Seasonings Bev...   \n",
       "3     Meat Spices and Seasonings Condiments Oil Vine...   \n",
       "4     Produce Spices and Seasonings Meat Spices and ...   \n",
       "...                                                 ...   \n",
       "4300  Milk Eggs Other Dairy Spices and Seasonings Ba...   \n",
       "4301  Milk Eggs Other Dairy Meat Spices and Seasonin...   \n",
       "4302  Beverages Milk Eggs Other Dairy Alcoholic Beve...   \n",
       "4303  Beverages Spices and Seasonings Canned and Jar...   \n",
       "4304  Beverages Baking Dried Fruits Produce Cheese P...   \n",
       "\n",
       "                                             diets  vegetarian  vegan  \\\n",
       "0                             lacto ovo vegetarian        True  False   \n",
       "1                             lacto ovo vegetarian        True  False   \n",
       "2                 dairy free; lacto ovo vegetarian        True  False   \n",
       "3     gluten free; dairy free; paleolithic; primal       False  False   \n",
       "4                                              NaN       False  False   \n",
       "...                                            ...         ...    ...   \n",
       "4300                          lacto ovo vegetarian        True   True   \n",
       "4301                                           NaN       False  False   \n",
       "4302             gluten free; lacto ovo vegetarian       False  False   \n",
       "4303       dairy free; lacto ovo vegetarian; vegan       False  False   \n",
       "4304                          lacto ovo vegetarian       False  False   \n",
       "\n",
       "      glutenFree  dairyFree  veryHealthy  cheap  veryPopular  sustainable  \\\n",
       "0          False      False        False  False        False        False   \n",
       "1          False      False        False  False        False        False   \n",
       "2          False       True        False  False        False        False   \n",
       "3           True       True        False  False        False        False   \n",
       "4          False      False        False  False        False        False   \n",
       "...          ...        ...          ...    ...          ...          ...   \n",
       "4300        True       True        False  False        False        False   \n",
       "4301        True       True         True  False        False        False   \n",
       "4302       False      False        False  False        False        False   \n",
       "4303        True      False         True  False        False        False   \n",
       "4304       False      False        False  False        False        False   \n",
       "\n",
       "      healthScore  pricePerServing  readyInMinutes  servings  \n",
       "0             3.0            75.55              45        10  \n",
       "1            15.0           147.70              45         2  \n",
       "2             1.0            26.06              45         9  \n",
       "3            17.0           242.23              45         4  \n",
       "4            12.0           417.69              45         4  \n",
       "...           ...              ...             ...       ...  \n",
       "4300          1.0           193.70              45         4  \n",
       "4301         63.0           493.63              30         2  \n",
       "4302          2.0           139.70              45        16  \n",
       "4303         90.0          1013.56              45         2  \n",
       "4304          2.0            90.13              45         8  \n",
       "\n",
       "[4305 rows x 18 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dbc7b",
   "metadata": {},
   "source": [
    "Avoid null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "426c9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diets'] = data['diets'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4842b3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>healthScore</th>\n",
       "      <th>pricePerServing</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4305.000000</td>\n",
       "      <td>4305.000000</td>\n",
       "      <td>4305.000000</td>\n",
       "      <td>4305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.432985</td>\n",
       "      <td>195.611954</td>\n",
       "      <td>56.468293</td>\n",
       "      <td>8.331010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.292771</td>\n",
       "      <td>249.970980</td>\n",
       "      <td>95.761049</td>\n",
       "      <td>10.626728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>70.100000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>139.700000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>250.630000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>8230.170000</td>\n",
       "      <td>3595.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       healthScore  pricePerServing  readyInMinutes     servings\n",
       "count  4305.000000      4305.000000     4305.000000  4305.000000\n",
       "mean     19.432985       195.611954       56.468293     8.331010\n",
       "std      23.292771       249.970980       95.761049    10.626728\n",
       "min       0.000000         0.930000        2.000000     1.000000\n",
       "25%       3.000000        70.100000       45.000000     4.000000\n",
       "50%      11.000000       139.700000       45.000000     6.000000\n",
       "75%      27.000000       250.630000       45.000000     8.000000\n",
       "max     100.000000      8230.170000     3595.000000   250.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "345b78c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4305 entries, 0 to 4304\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   title             4305 non-null   object \n",
      " 1   summary           4300 non-null   object \n",
      " 2   instructions      4104 non-null   object \n",
      " 3   ingredients       4305 non-null   object \n",
      " 4   ingredient types  4305 non-null   object \n",
      " 5   diets             4305 non-null   object \n",
      " 6   vegetarian        4305 non-null   bool   \n",
      " 7   vegan             4305 non-null   bool   \n",
      " 8   glutenFree        4305 non-null   bool   \n",
      " 9   dairyFree         4305 non-null   bool   \n",
      " 10  veryHealthy       4305 non-null   bool   \n",
      " 11  cheap             4305 non-null   bool   \n",
      " 12  veryPopular       4305 non-null   bool   \n",
      " 13  sustainable       4305 non-null   bool   \n",
      " 14  healthScore       4305 non-null   float64\n",
      " 15  pricePerServing   4305 non-null   float64\n",
      " 16  readyInMinutes    4305 non-null   int64  \n",
      " 17  servings          4305 non-null   int64  \n",
      "dtypes: bool(8), float64(2), int64(2), object(6)\n",
      "memory usage: 370.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a2c66",
   "metadata": {},
   "source": [
    "healthScore was actually int values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "179ad93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.healthScore = data.healthScore.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3f2c8",
   "metadata": {},
   "source": [
    "The other float one is price, can be round , no such a big diference on the meaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b60564",
   "metadata": {},
   "source": [
    "First selection of variables to try de model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed90d2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>healthScore</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>yakitori glaze</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>63</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>white chocolate cheesecake with raspberries</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>fish pie with fresh and smoked salmon</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>mushroom  bacon  pull apart bread</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4305 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  healthScore  \\\n",
       "0                 orange fig teacake with caramel glaze            3   \n",
       "1     poached eggs on a bed of fried mushrooms and c...           15   \n",
       "2                                   pandan chiffon cake            1   \n",
       "3              pork chop with honey  mustard and apples           17   \n",
       "4        beet gnocchi with steak and brown butter sauce           12   \n",
       "...                                                 ...          ...   \n",
       "4300                                     yakitori glaze            1   \n",
       "4301  pan seared honey glazed salmon with collard gr...           63   \n",
       "4302        white chocolate cheesecake with raspberries            2   \n",
       "4303              fish pie with fresh and smoked salmon           90   \n",
       "4304                  mushroom  bacon  pull apart bread            2   \n",
       "\n",
       "      readyInMinutes  servings  \n",
       "0                 45        10  \n",
       "1                 45         2  \n",
       "2                 45         9  \n",
       "3                 45         4  \n",
       "4                 45         4  \n",
       "...              ...       ...  \n",
       "4300              45         4  \n",
       "4301              30         2  \n",
       "4302              45        16  \n",
       "4303              45         2  \n",
       "4304              45         8  \n",
       "\n",
       "[4305 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex = data.iloc[:,[0,-4,-2,-1]]\n",
    "tex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242eba99",
   "metadata": {},
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bd2e3",
   "metadata": {},
   "source": [
    "## Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6eefd508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in c:\\users\\sarab\\anaconda3\\lib\\site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "! pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b844b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-a7064eb2ddad>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tex['cols']=lista\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "lista=[]\n",
    "for fila in tex[\"instructions\"]:\n",
    "    fil=fila.lower()\n",
    "    #delete links\n",
    "    sinwebs=re.sub(r\"https\\S+|https\\S+|www\\S+\",'',fil,flags=re.MULTILINE)\n",
    "    #tokenize\n",
    "    tok=word_tokenize(sinwebs)\n",
    "    filaa=[]\n",
    "    for pal in tok:\n",
    "        #delete stopwords\n",
    "        if pal not in stop_words:\n",
    "            if pal.isalnum():\n",
    "                #stemize\n",
    "                z=ps.stem(pal)\n",
    "                #lematize\n",
    "                zz=lemmatizer.lemmatize(z)\n",
    "                filaa.append(zz)\n",
    "    lista.append(filaa) \n",
    "tex['cols']=lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08155f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>healthScore</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>[orang, fig, teacak, caramel, glaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[poach, egg, bed, fri, mushroom, countri, whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>[pandan, chiffon, cake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[pork, chop, honey, mustard, appl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[beet, gnocchi, steak, brown, butter, sauc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>yakitori glaze</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[yakitori, glaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>63</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>[pan, sear, honey, glaze, salmon, collard, green]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>white chocolate cheesecake with raspberries</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>[white, chocol, cheesecak, raspberri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>fish pie with fresh and smoked salmon</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[fish, pie, fresh, smoke, salmon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>mushroom  bacon  pull apart bread</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>[mushroom, bacon, pull, apart, bread]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  healthScore  \\\n",
       "0                 orange fig teacake with caramel glaze            3   \n",
       "1     poached eggs on a bed of fried mushrooms and c...           15   \n",
       "2                                   pandan chiffon cake            1   \n",
       "3              pork chop with honey  mustard and apples           17   \n",
       "4        beet gnocchi with steak and brown butter sauce           12   \n",
       "...                                                 ...          ...   \n",
       "4300                                     yakitori glaze            1   \n",
       "4301  pan seared honey glazed salmon with collard gr...           63   \n",
       "4302        white chocolate cheesecake with raspberries            2   \n",
       "4303              fish pie with fresh and smoked salmon           90   \n",
       "4304                  mushroom  bacon  pull apart bread            2   \n",
       "\n",
       "      readyInMinutes  servings  \\\n",
       "0                 45        10   \n",
       "1                 45         2   \n",
       "2                 45         9   \n",
       "3                 45         4   \n",
       "4                 45         4   \n",
       "...              ...       ...   \n",
       "4300              45         4   \n",
       "4301              30         2   \n",
       "4302              45        16   \n",
       "4303              45         2   \n",
       "4304              45         8   \n",
       "\n",
       "                                                   cols  \n",
       "0                  [orang, fig, teacak, caramel, glaze]  \n",
       "1     [poach, egg, bed, fri, mushroom, countri, whit...  \n",
       "2                               [pandan, chiffon, cake]  \n",
       "3                    [pork, chop, honey, mustard, appl]  \n",
       "4           [beet, gnocchi, steak, brown, butter, sauc]  \n",
       "...                                                 ...  \n",
       "4300                                  [yakitori, glaze]  \n",
       "4301  [pan, sear, honey, glaze, salmon, collard, green]  \n",
       "4302              [white, chocol, cheesecak, raspberri]  \n",
       "4303                  [fish, pie, fresh, smoke, salmon]  \n",
       "4304              [mushroom, bacon, pull, apart, bread]  \n",
       "\n",
       "[4305 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf97005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = tex['title']\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# print(vectorizer.vocabulary_)\n",
    "vector = vectorizer.transform(text)\n",
    "# resultado\n",
    "print(vector.shape)#num de docs por number of words\n",
    "print(type(vector))\n",
    "print(vector.toarray())\n",
    "### Correct typos\n",
    "co=tex[\"cols\"]\n",
    "listatodo=[]\n",
    "for i in co:\n",
    "    for j in i:\n",
    "        if j not in listatodo:\n",
    "            listatodo.append(j)\n",
    "#print(listatodo)\n",
    "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
    "counts = ngram_vectorizer.fit_transform(listatodo)\n",
    "#ngram_vectorizer.get_feature_names()\n",
    "counts.toarray().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "60fa6e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.57600521 8.26915239 8.26915239 ... 8.26915239 5.43593905 8.6746175 ]\n",
      "(4305, 2333)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = tex['title']\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "# print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "# print(vector.shape)\n",
    "vector = vectorizer.transform(text)\n",
    "# resultado\n",
    "print(vector.shape)#num de doscs por numero de palabras\n",
    "print(type(vector))\n",
    "v=vector.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12689acf",
   "metadata": {},
   "source": [
    "## DIVISION TRAIN - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "701d36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(v, data['readyInMinutes'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9650da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(v, data['readyInMinutes'], test_size=0.3, random_state=42)pocas=X_train\n",
    "pocasy=y_train\n",
    "pocast=X_eval\n",
    "pocasyt=y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36235b13",
   "metadata": {},
   "source": [
    "# REGRESION METHODS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f716c4",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "745a4a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 9.559314727783203s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "clf = LogisticRegression()\n",
    "clf.fit(pocas, pocasy)\n",
    "pred = clf.predict(pocast)\n",
    "score = f1_score(pocasyt, pred, average='macro')\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5dd0c48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011985058446455504"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e2a3b",
   "metadata": {},
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4954e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c292278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 90.22060346603394s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05409721870679238"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "#rbf model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorerbf= f1_score(y_eval, pred, average='macro')\n",
    "scorerbf\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorerbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ee32f461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 33.157859563827515s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017099240480861127"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = svm.SVC(C=0.5,kernel='linear')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorelineal = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorelineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6329dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 331.6145942211151s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11243298758973122"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "clf = svm.SVC(C=0.5,kernel='linear',class_weight='balanced')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorelineal = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorelineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1cc7b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 352.9163384437561s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12187760005910254"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "clf = svm.SVC(kernel='poly')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorepoly = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorepoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "49195fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 515.7796738147736s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19364492347270784"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = svm.SVC(kernel='poly',class_weight='balanced')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorepoly = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorepoly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf34b11",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f93c3c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 31.630287170410156s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05409721870679238"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(pocas, pocasy)\n",
    "clf.predict(pocast)\n",
    "score = f1_score(pocasyt, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0473953",
   "metadata": {},
   "source": [
    "## perceptron multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "371f93aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 94.48288249969482s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05409721870679238"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf.fit(pocas, pocasy)\n",
    "clf.predict(pocast)\n",
    "score = f1_score(pocasyt, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2c5be",
   "metadata": {},
   "source": [
    "### REPEATED ( Changing the input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c0693a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructions</th>\n",
       "      <th>healthScore</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>combine all ingredients in a small saucepan a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>instructions collard greens using a non stick ...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>to make the crumb crust in a small bowl combin...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>peel potatoes and cut into chunks cook in boi...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>lay the yeast rolls out on the counter until t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4305 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           instructions  healthScore  \\\n",
       "0      you will need a 9  springform pan  or a cake ...          3.0   \n",
       "1      in a frying pan heat up oil then add mushroom...         15.0   \n",
       "2      preheat the oven to 170c  blend the pandan le...          1.0   \n",
       "3      pre heat your oven to 200c   400f  line a roa...         17.0   \n",
       "4     cooking beets heat oven to 400 degrees wash be...         12.0   \n",
       "...                                                 ...          ...   \n",
       "4300   combine all ingredients in a small saucepan a...          1.0   \n",
       "4301  instructions collard greens using a non stick ...         63.0   \n",
       "4302  to make the crumb crust in a small bowl combin...          2.0   \n",
       "4303   peel potatoes and cut into chunks cook in boi...         90.0   \n",
       "4304  lay the yeast rolls out on the counter until t...          2.0   \n",
       "\n",
       "      readyInMinutes  servings  \n",
       "0                 45        10  \n",
       "1                 45         2  \n",
       "2                 45         9  \n",
       "3                 45         4  \n",
       "4                 45         4  \n",
       "...              ...       ...  \n",
       "4300              45         4  \n",
       "4301              30         2  \n",
       "4302              45        16  \n",
       "4303              45         2  \n",
       "4304              45         8  \n",
       "\n",
       "[4305 rows x 4 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex = data.iloc[:,[3,-4,-2,-1]]\n",
    "tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "500b11f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-295-96b7fc8e0212>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tex['cols1']=lista\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "lista=[]\n",
    "for fila in tex[\"instructions\"]:\n",
    "    try:\n",
    "            fil=fila.lower()\n",
    "    except : pass\n",
    "        #eliminar webs y https\n",
    "    sinwebs=re.sub(r\"https\\S+|https\\S+|www\\S+\",'',fil,flags=re.MULTILINE)\n",
    "    #tokenizar\n",
    "    tok=word_tokenize(sinwebs)\n",
    "    filaa=[]\n",
    "    for pal in tok:\n",
    "        #eliminar stopwords\n",
    "        if pal not in stop_words:\n",
    "            if pal.isalnum():\n",
    "                #stemizar\n",
    "                z=ps.stem(pal)\n",
    "                #lematizar\n",
    "                zz=lemmatizer.lemmatize(z)\n",
    "                filaa.append(zz)\n",
    "    lista.append(filaa) \n",
    "tex['cols1']=lista\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "049edccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(v, data['readyInMinutes'], test_size=0.3, random_state=42)\n",
    "pocas=X_train\n",
    "pocasy=y_train\n",
    "pocast=X_eval\n",
    "pocasyt=y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1c60cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training comleted in 9.719621181488037s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "clf = LogisticRegression()\n",
    "clf.fit(pocas, pocasy)\n",
    "pred = clf.predict(pocast)\n",
    "score = f1_score(pocasyt, pred, average='macro')\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "44c5b4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05409721870679238\n",
      "Training comleted in 88.35710620880127s.\n",
      "0.19364492347270784\n",
      "Training comleted in 33.12643003463745s.\n",
      "0.017099240480861127\n",
      "Training comleted in 330.2898299694061s.\n",
      "0.11243298758973122\n",
      "Training comleted in 358.275545835495s.\n",
      "0.12187760005910254\n",
      "Training comleted in 525.1029150485992s.\n",
      "0.19364492347270784\n",
      "Training comleted in 557.2320039272308s.\n",
      "0.19364492347270784\n",
      "Training comleted in 92.99646496772766s.\n",
      "0.19364492347270784\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#rbf model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorerbf= f1_score(y_eval, pred, average='macro')\n",
    "print(scorerbf)\n",
    "scorerbf\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "score\n",
    "print(score)\n",
    "start = time.time()\n",
    "clf = svm.SVC(C=0.5,kernel='linear')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorelineal = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorelineal\n",
    "print(scorelineal)\n",
    "start = time.time()\n",
    "clf = svm.SVC(C=0.5,kernel='linear',class_weight='balanced')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorelineal = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorelineal\n",
    "print(scorelineal)\n",
    "\n",
    "start = time.time()\n",
    "clf = svm.SVC(kernel='poly')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorepoly = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorepoly\n",
    "print(scorepoly)\n",
    "\n",
    "start = time.time()\n",
    "clf = svm.SVC(kernel='poly',class_weight='balanced')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_eval)\n",
    "scorepoly = f1_score(y_eval, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "scorepoly\n",
    "print(scorepoly)\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(pocas, pocasy)\n",
    "clf.predict(pocast)\n",
    "score = f1_score(pocasyt, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "score\n",
    "print(score)\n",
    "start = time.time()\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf.fit(pocas, pocasy)\n",
    "clf.predict(pocast)\n",
    "score = f1_score(pocasyt, pred, average='macro')\n",
    "end = time.time()\n",
    "print(f\"Training comleted in {end-start}s.\")\n",
    "score\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8518b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sarab\\anaconda3\\lib\\site-packages (4.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\sarab\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08ec9ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                              title  \\\n",
      "10            10                                 broiled crab cakes   \n",
      "3580          75                                little italy burger   \n",
      "3123          19                      carrot raisin pineapple salad   \n",
      "2640          73                      cheesy mexican turkey burgers   \n",
      "1530          30  15 minute tamari marinated steak salad [paleo ...   \n",
      "\n",
      "                                                summary  \\\n",
      "10    broiled crab cakes takes around approximately ...   \n",
      "3580  little italy burger might be just the american...   \n",
      "3123  carrot raisin pineapple salad is a gluten free...   \n",
      "2640  cheesy mexican turkey burgers is a gluten free...   \n",
      "1530  15 minute tamari marinated steak salad [paleo ...   \n",
      "\n",
      "                                           instructions  \\\n",
      "10    place all of the ingredients  except the butte...   \n",
      "3580  heat the grill to high  divide the ground beef...   \n",
      "3123   prepare ingredients  mix together and stir well    \n",
      "2640                                                NaN   \n",
      "1530   marinade the steak in the tamari soy sauce  p...   \n",
      "\n",
      "                                            ingredients  \\\n",
      "10    crabmeat; saltine crackers; parsley; peppers; ...   \n",
      "3580  basil; cooked pasta; garlic; lemon juice; oliv...   \n",
      "3123  ground flaxseed; water; wheat bran; bran; spel...   \n",
      "2640  cilantro leaves; cooked black beans; cotija ch...   \n",
      "1530  banana shallots; bay leaf; canned chickpeas; c...   \n",
      "\n",
      "                                       ingredient types        diets  \\\n",
      "10    Seafood Milk Eggs Other Dairy Spices and Seaso...  pescatarian   \n",
      "3580  Pasta and Rice Produce Spices and Seasonings C...          NaN   \n",
      "3123  Pasta and Rice Health Foods Dried Fruits Produ...          NaN   \n",
      "2640  Seafood Spices and Seasonings Pasta and Rice C...  pescatarian   \n",
      "1530  Canned and Jarred Spices and Seasonings Oil Vi...          NaN   \n",
      "\n",
      "      vegetarian  vegan  glutenFree  dairyFree  veryHealthy  cheap  \\\n",
      "10         False  False       False      False        False  False   \n",
      "3580       False  False       False      False        False  False   \n",
      "3123        True  False        True      False        False  False   \n",
      "2640       False  False        True      False        False  False   \n",
      "1530       False  False        True       True        False  False   \n",
      "\n",
      "      veryPopular  sustainable  healthScore  pricePerServing  readyInMinutes  \\\n",
      "10          False        False         24.0           291.95              45   \n",
      "3580        False        False         12.0           461.22              45   \n",
      "3123        False        False         14.0            95.68              45   \n",
      "2640        False        False         12.0           228.04              35   \n",
      "1530        False        False         22.0           450.47              15   \n",
      "\n",
      "      servings  \n",
      "10           3  \n",
      "3580         4  \n",
      "3123        10  \n",
      "2640         4  \n",
      "1530         2  \n",
      "Distribution of data based on labels:  45     3101\n",
      "30      183\n",
      "60       91\n",
      "10       70\n",
      "15       64\n",
      "       ... \n",
      "74        1\n",
      "78        1\n",
      "82        1\n",
      "190       1\n",
      "735       1\n",
      "Name: readyInMinutes, Length: 130, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sentence before tokenization:  pandan chiffon cake\n",
      "Encoded Input from dataset:  [101, 25462, 2078, 9610, 4246, 2239, 9850, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "df=pd.read_csv('C:/Users/sarab/Downloads/cleaneddata.csv')\n",
    "print(df.sample(5))\n",
    "\n",
    "## create label and sentence list\n",
    "sentences = df.title.values #TEXTO\n",
    "\n",
    "#check distribution of data based on labels\n",
    "print(\"Distribution of data based on labels: \",df.readyInMinutes.value_counts())#CLASSIFICACION\n",
    "\n",
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = 512\n",
    "\n",
    "## Import BERT tokenizer, that is used to convert our text into tokens that corresponds to BERT library\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "input_ids = [tokenizer.encode(sent, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) for sent in sentences]\n",
    "readyInMinutes = df.readyInMinutes.values\n",
    "\n",
    "print(\"Actual sentence before tokenization: \",sentences[2])\n",
    "print(\"Encoded Input from dataset: \",input_ids[2])\n",
    "\n",
    "## Create attention mask\n",
    "attention_masks = []\n",
    "## Create a mask of 1 for all input tokens and 0 for all padding tokens\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "print(attention_masks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5e5a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3de3ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-96-a7064eb2ddad>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tex['cols']=lista\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "lista=[]\n",
    "for fila in tex[\"title\"]:\n",
    "    fil=fila.lower()\n",
    "    #eliminar webs y https\n",
    "    sinwebs=re.sub(r\"https\\S+|https\\S+|www\\S+\",'',fil,flags=re.MULTILINE)\n",
    "    #tokenizar\n",
    "    tok=word_tokenize(sinwebs)\n",
    "    filaa=[]\n",
    "    for pal in tok:\n",
    "        #eliminar stopwords\n",
    "        if pal not in stop_words:\n",
    "            if pal.isalnum():\n",
    "                #stemizar\n",
    "                z=ps.stem(pal)\n",
    "                #lematizar\n",
    "                zz=lemmatizer.lemmatize(z)\n",
    "                filaa.append(zz)\n",
    "    lista.append(filaa) \n",
    "tex['cols']=lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e0f4c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>healthScore</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>[orang, fig, teacak, caramel, glaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[poach, egg, bed, fri, mushroom, countri, whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>[pandan, chiffon, cake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[pork, chop, honey, mustard, appl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[beet, gnocchi, steak, brown, butter, sauc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>yakitori glaze</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[yakitori, glaze]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>63</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>[pan, sear, honey, glaze, salmon, collard, green]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>white chocolate cheesecake with raspberries</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>[white, chocol, cheesecak, raspberri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>fish pie with fresh and smoked salmon</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[fish, pie, fresh, smoke, salmon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>mushroom  bacon  pull apart bread</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>[mushroom, bacon, pull, apart, bread]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  healthScore  \\\n",
       "0                 orange fig teacake with caramel glaze            3   \n",
       "1     poached eggs on a bed of fried mushrooms and c...           15   \n",
       "2                                   pandan chiffon cake            1   \n",
       "3              pork chop with honey  mustard and apples           17   \n",
       "4        beet gnocchi with steak and brown butter sauce           12   \n",
       "...                                                 ...          ...   \n",
       "4300                                     yakitori glaze            1   \n",
       "4301  pan seared honey glazed salmon with collard gr...           63   \n",
       "4302        white chocolate cheesecake with raspberries            2   \n",
       "4303              fish pie with fresh and smoked salmon           90   \n",
       "4304                  mushroom  bacon  pull apart bread            2   \n",
       "\n",
       "      readyInMinutes  servings  \\\n",
       "0                 45        10   \n",
       "1                 45         2   \n",
       "2                 45         9   \n",
       "3                 45         4   \n",
       "4                 45         4   \n",
       "...              ...       ...   \n",
       "4300              45         4   \n",
       "4301              30         2   \n",
       "4302              45        16   \n",
       "4303              45         2   \n",
       "4304              45         8   \n",
       "\n",
       "                                                   cols  \n",
       "0                  [orang, fig, teacak, caramel, glaze]  \n",
       "1     [poach, egg, bed, fri, mushroom, countri, whit...  \n",
       "2                               [pandan, chiffon, cake]  \n",
       "3                    [pork, chop, honey, mustard, appl]  \n",
       "4           [beet, gnocchi, steak, brown, butter, sauc]  \n",
       "...                                                 ...  \n",
       "4300                                  [yakitori, glaze]  \n",
       "4301  [pan, sear, honey, glaze, salmon, collard, green]  \n",
       "4302              [white, chocol, cheesecak, raspberri]  \n",
       "4303                  [fish, pie, fresh, smoke, salmon]  \n",
       "4304              [mushroom, bacon, pull, apart, bread]  \n",
       "\n",
       "[4305 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230aea46",
   "metadata": {},
   "source": [
    "Select variables, 0:5 text , -4: num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5697724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data.iloc[:,[0,1,2,3,4,5,-4,-3,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "35ff9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-272-87a3aaa77e76>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  t[i+'lema']=lista\n"
     ]
    }
   ],
   "source": [
    "t1 = t\n",
    "for i in list(t.columns[0:6]):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    lista=[]\n",
    "    for fila in t[i]:\n",
    "        try:\n",
    "            fil=fila.lower()\n",
    "        except : pass\n",
    "        #eliminar webs y https\n",
    "        sinwebs=re.sub(r\"https\\S+|https\\S+|www\\S+\",'',fil,flags=re.MULTILINE)\n",
    "        #tokenizar\n",
    "        tok=word_tokenize(sinwebs)\n",
    "        filaa=[]\n",
    "        for pal in tok:\n",
    "            #eliminar stopwords\n",
    "            if pal not in stop_words:\n",
    "                if pal.isalnum():\n",
    "                    #stemizar\n",
    "                    z=ps.stem(pal)\n",
    "                    #lematizar\n",
    "                    zz=lemmatizer.lemmatize(z)\n",
    "                    filaa.append(zz)\n",
    "        lista.append(filaa) \n",
    "    t[i+'lema']=lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f502010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient types</th>\n",
       "      <th>diets</th>\n",
       "      <th>healthScore</th>\n",
       "      <th>pricePerServing</th>\n",
       "      <th>readyInMinutes</th>\n",
       "      <th>servings</th>\n",
       "      <th>titlelema</th>\n",
       "      <th>summarylema</th>\n",
       "      <th>instructionslema</th>\n",
       "      <th>ingredientslema</th>\n",
       "      <th>ingredient typeslema</th>\n",
       "      <th>dietslema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange fig teacake with caramel glaze</td>\n",
       "      <td>orange fig teacake with caramel glaze is a veg...</td>\n",
       "      <td>you will need a 9  springform pan  or a cake ...</td>\n",
       "      <td>ap flour; baking powder; cardamom; eggs; fresh...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>3</td>\n",
       "      <td>75.55</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>[orang, fig, teacak, caramel, glaze]</td>\n",
       "      <td>[orang, fig, teacak, caramel, glaze, vegetaria...</td>\n",
       "      <td>[need, 9, springform, pan, cake, pan, least, 2...</td>\n",
       "      <td>[ap, flour, bake, powder, cardamom, egg, fresh...</td>\n",
       "      <td>[beverag, milk, egg, dairi, spice, season, bak...</td>\n",
       "      <td>[lacto, ovo, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>poached eggs on a bed of fried mushrooms and c...</td>\n",
       "      <td>in a frying pan heat up oil then add mushroom...</td>\n",
       "      <td>bread; butter; eggs; eggs; mushrooms; oil; sal...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Spices and Sea...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>15</td>\n",
       "      <td>147.70</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[poach, egg, bed, fri, mushroom, countri, whit...</td>\n",
       "      <td>[poach, egg, bed, fri, mushroom, countri, whit...</td>\n",
       "      <td>[fri, pan, heat, oil, add, mushroom, saut, 5, ...</td>\n",
       "      <td>[bread, butter, egg, egg, mushroom, oil, salt,...</td>\n",
       "      <td>[beverag, milk, egg, dairi, spice, season, oil...</td>\n",
       "      <td>[lacto, ovo, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandan chiffon cake</td>\n",
       "      <td>for 26 cents per serving   this recipe covers ...</td>\n",
       "      <td>preheat the oven to 170c  blend the pandan le...</td>\n",
       "      <td>all purpose flour; bay leaves; coconut milk; c...</td>\n",
       "      <td>Ethnic Foods Produce Spices and Seasonings Bev...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian</td>\n",
       "      <td>1</td>\n",
       "      <td>26.06</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>[pandan, chiffon, cake]</td>\n",
       "      <td>[26, cent, per, serv, recip, cover, 3, daili, ...</td>\n",
       "      <td>[preheat, oven, 170c, blend, pandan, leav, wat...</td>\n",
       "      <td>[purpos, flour, bay, leav, coconut, milk, corn...</td>\n",
       "      <td>[ethnic, food, produc, spice, season, beverag,...</td>\n",
       "      <td>[dairi, free, lacto, ovo, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pork chop with honey  mustard and apples</td>\n",
       "      <td>pork chop with honey  mustard and apples might...</td>\n",
       "      <td>pre heat your oven to 200c   400f  line a roa...</td>\n",
       "      <td>apples; dijon mustard; garlic cloves; honey; j...</td>\n",
       "      <td>Meat Spices and Seasonings Condiments Oil Vine...</td>\n",
       "      <td>gluten free; dairy free; paleolithic; primal</td>\n",
       "      <td>17</td>\n",
       "      <td>242.23</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[pork, chop, honey, mustard, appl]</td>\n",
       "      <td>[pork, chop, honey, mustard, appl, might, main...</td>\n",
       "      <td>[pre, heat, oven, 200c, 400f, line, roast, tin...</td>\n",
       "      <td>[appl, dijon, mustard, garlic, clove, honey, j...</td>\n",
       "      <td>[meat, spice, season, condiment, oil, vinegar,...</td>\n",
       "      <td>[gluten, free, dairi, free, paleolith, primal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beet gnocchi with steak and brown butter sauce</td>\n",
       "      <td>the recipe beet gnocchi with steak and brown b...</td>\n",
       "      <td>cooking beets heat oven to 400 degrees wash be...</td>\n",
       "      <td>gnocchi; beets; olive oil; s p; goat cheese; r...</td>\n",
       "      <td>Produce Spices and Seasonings Meat Spices and ...</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>417.69</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[beet, gnocchi, steak, brown, butter, sauc]</td>\n",
       "      <td>[recip, beet, gnocchi, steak, brown, butter, s...</td>\n",
       "      <td>[cook, beet, heat, oven, 400, degre, wash, bee...</td>\n",
       "      <td>[gnocchi, beet, oliv, oil, p, goat, chees, ric...</td>\n",
       "      <td>[produc, spice, season, meat, spice, season, m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>yakitori glaze</td>\n",
       "      <td>yakitori glaze might be just the japanese reci...</td>\n",
       "      <td>combine all ingredients in a small saucepan a...</td>\n",
       "      <td>butter; egg yolks; flour; orange zest; poppy s...</td>\n",
       "      <td>Milk Eggs Other Dairy Spices and Seasonings Ba...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>1</td>\n",
       "      <td>193.70</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>[yakitori, glaze]</td>\n",
       "      <td>[yakitori, glaze, might, japanes, recip, searc...</td>\n",
       "      <td>[combin, ingredi, small, saucepan, bring, boil...</td>\n",
       "      <td>[butter, egg, yolk, flour, orang, zest, poppi,...</td>\n",
       "      <td>[milk, egg, dairi, spice, season, bake, spice,...</td>\n",
       "      <td>[lacto, ovo, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>pan seared honey glazed salmon with collard gr...</td>\n",
       "      <td>instructions collard greens using a non stick ...</td>\n",
       "      <td>unbaked pie crust; shredded cheddar cheese; ja...</td>\n",
       "      <td>Milk Eggs Other Dairy Meat Spices and Seasonin...</td>\n",
       "      <td></td>\n",
       "      <td>63</td>\n",
       "      <td>493.63</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>[pan, sear, honey, glaze, salmon, collard, green]</td>\n",
       "      <td>[pan, sear, honey, glaze, salmon, collard, gre...</td>\n",
       "      <td>[instruct, collard, green, use, non, stick, pa...</td>\n",
       "      <td>[unbak, pie, crust, shred, cheddar, chees, jac...</td>\n",
       "      <td>[milk, egg, dairi, meat, spice, season, bake, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>white chocolate cheesecake with raspberries</td>\n",
       "      <td>the recipe white chocolate cheesecake with ras...</td>\n",
       "      <td>to make the crumb crust in a small bowl combin...</td>\n",
       "      <td>egg yolks; grand marnier; light brown sugar; o...</td>\n",
       "      <td>Beverages Milk Eggs Other Dairy Alcoholic Beve...</td>\n",
       "      <td>gluten free; lacto ovo vegetarian</td>\n",
       "      <td>2</td>\n",
       "      <td>139.70</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>[white, chocol, cheesecak, raspberri]</td>\n",
       "      <td>[recip, white, chocol, cheesecak, raspberri, m...</td>\n",
       "      <td>[make, crumb, crust, small, bowl, combin, grah...</td>\n",
       "      <td>[egg, yolk, grand, marnier, light, brown, suga...</td>\n",
       "      <td>[beverag, milk, egg, dairi, alcohol, beverag, ...</td>\n",
       "      <td>[gluten, free, lacto, ovo, vegetarian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>fish pie with fresh and smoked salmon</td>\n",
       "      <td>this recipe makes 2 servings with 710 calories...</td>\n",
       "      <td>peel potatoes and cut into chunks cook in boi...</td>\n",
       "      <td>cashew; cumin; eggplant; flour; garam masala; ...</td>\n",
       "      <td>Beverages Spices and Seasonings Canned and Jar...</td>\n",
       "      <td>dairy free; lacto ovo vegetarian; vegan</td>\n",
       "      <td>90</td>\n",
       "      <td>1013.56</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>[fish, pie, fresh, smoke, salmon]</td>\n",
       "      <td>[recip, make, 2, serv, 710, calori, 47g, prote...</td>\n",
       "      <td>[peel, potato, cut, chunk, cook, boil, salt, w...</td>\n",
       "      <td>[cashew, cumin, eggplant, flour, garam, masala...</td>\n",
       "      <td>[beverag, spice, season, can, jar, nut, savori...</td>\n",
       "      <td>[dairi, free, lacto, ovo, vegetarian, vegan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>mushroom  bacon  pull apart bread</td>\n",
       "      <td>the recipe mushroom  bacon  pull apart bread c...</td>\n",
       "      <td>lay the yeast rolls out on the counter until t...</td>\n",
       "      <td>puff pastry; brie; dried figs; apple juice; su...</td>\n",
       "      <td>Beverages Baking Dried Fruits Produce Cheese P...</td>\n",
       "      <td>lacto ovo vegetarian</td>\n",
       "      <td>2</td>\n",
       "      <td>90.13</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>[mushroom, bacon, pull, apart, bread]</td>\n",
       "      <td>[recip, mushroom, bacon, pull, apart, bread, m...</td>\n",
       "      <td>[lay, yeast, roll, counter, becom, soft, compl...</td>\n",
       "      <td>[puff, pastri, brie, dri, fig, appl, juic, sug...</td>\n",
       "      <td>[beverag, bake, dri, fruit, produc, chees, pro...</td>\n",
       "      <td>[lacto, ovo, vegetarian]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4305 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                 orange fig teacake with caramel glaze   \n",
       "1     poached eggs on a bed of fried mushrooms and c...   \n",
       "2                                   pandan chiffon cake   \n",
       "3              pork chop with honey  mustard and apples   \n",
       "4        beet gnocchi with steak and brown butter sauce   \n",
       "...                                                 ...   \n",
       "4300                                     yakitori glaze   \n",
       "4301  pan seared honey glazed salmon with collard gr...   \n",
       "4302        white chocolate cheesecake with raspberries   \n",
       "4303              fish pie with fresh and smoked salmon   \n",
       "4304                  mushroom  bacon  pull apart bread   \n",
       "\n",
       "                                                summary  \\\n",
       "0     orange fig teacake with caramel glaze is a veg...   \n",
       "1     poached eggs on a bed of fried mushrooms and c...   \n",
       "2     for 26 cents per serving   this recipe covers ...   \n",
       "3     pork chop with honey  mustard and apples might...   \n",
       "4     the recipe beet gnocchi with steak and brown b...   \n",
       "...                                                 ...   \n",
       "4300  yakitori glaze might be just the japanese reci...   \n",
       "4301  pan seared honey glazed salmon with collard gr...   \n",
       "4302  the recipe white chocolate cheesecake with ras...   \n",
       "4303  this recipe makes 2 servings with 710 calories...   \n",
       "4304  the recipe mushroom  bacon  pull apart bread c...   \n",
       "\n",
       "                                           instructions  \\\n",
       "0      you will need a 9  springform pan  or a cake ...   \n",
       "1      in a frying pan heat up oil then add mushroom...   \n",
       "2      preheat the oven to 170c  blend the pandan le...   \n",
       "3      pre heat your oven to 200c   400f  line a roa...   \n",
       "4     cooking beets heat oven to 400 degrees wash be...   \n",
       "...                                                 ...   \n",
       "4300   combine all ingredients in a small saucepan a...   \n",
       "4301  instructions collard greens using a non stick ...   \n",
       "4302  to make the crumb crust in a small bowl combin...   \n",
       "4303   peel potatoes and cut into chunks cook in boi...   \n",
       "4304  lay the yeast rolls out on the counter until t...   \n",
       "\n",
       "                                            ingredients  \\\n",
       "0     ap flour; baking powder; cardamom; eggs; fresh...   \n",
       "1     bread; butter; eggs; eggs; mushrooms; oil; sal...   \n",
       "2     all purpose flour; bay leaves; coconut milk; c...   \n",
       "3     apples; dijon mustard; garlic cloves; honey; j...   \n",
       "4     gnocchi; beets; olive oil; s p; goat cheese; r...   \n",
       "...                                                 ...   \n",
       "4300  butter; egg yolks; flour; orange zest; poppy s...   \n",
       "4301  unbaked pie crust; shredded cheddar cheese; ja...   \n",
       "4302  egg yolks; grand marnier; light brown sugar; o...   \n",
       "4303  cashew; cumin; eggplant; flour; garam masala; ...   \n",
       "4304  puff pastry; brie; dried figs; apple juice; su...   \n",
       "\n",
       "                                       ingredient types  \\\n",
       "0     Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "1     Beverages Milk Eggs Other Dairy Spices and Sea...   \n",
       "2     Ethnic Foods Produce Spices and Seasonings Bev...   \n",
       "3     Meat Spices and Seasonings Condiments Oil Vine...   \n",
       "4     Produce Spices and Seasonings Meat Spices and ...   \n",
       "...                                                 ...   \n",
       "4300  Milk Eggs Other Dairy Spices and Seasonings Ba...   \n",
       "4301  Milk Eggs Other Dairy Meat Spices and Seasonin...   \n",
       "4302  Beverages Milk Eggs Other Dairy Alcoholic Beve...   \n",
       "4303  Beverages Spices and Seasonings Canned and Jar...   \n",
       "4304  Beverages Baking Dried Fruits Produce Cheese P...   \n",
       "\n",
       "                                             diets  healthScore  \\\n",
       "0                             lacto ovo vegetarian            3   \n",
       "1                             lacto ovo vegetarian           15   \n",
       "2                 dairy free; lacto ovo vegetarian            1   \n",
       "3     gluten free; dairy free; paleolithic; primal           17   \n",
       "4                                                            12   \n",
       "...                                            ...          ...   \n",
       "4300                          lacto ovo vegetarian            1   \n",
       "4301                                                         63   \n",
       "4302             gluten free; lacto ovo vegetarian            2   \n",
       "4303       dairy free; lacto ovo vegetarian; vegan           90   \n",
       "4304                          lacto ovo vegetarian            2   \n",
       "\n",
       "      pricePerServing  readyInMinutes  servings  \\\n",
       "0               75.55              45        10   \n",
       "1              147.70              45         2   \n",
       "2               26.06              45         9   \n",
       "3              242.23              45         4   \n",
       "4              417.69              45         4   \n",
       "...               ...             ...       ...   \n",
       "4300           193.70              45         4   \n",
       "4301           493.63              30         2   \n",
       "4302           139.70              45        16   \n",
       "4303          1013.56              45         2   \n",
       "4304            90.13              45         8   \n",
       "\n",
       "                                              titlelema  \\\n",
       "0                  [orang, fig, teacak, caramel, glaze]   \n",
       "1     [poach, egg, bed, fri, mushroom, countri, whit...   \n",
       "2                               [pandan, chiffon, cake]   \n",
       "3                    [pork, chop, honey, mustard, appl]   \n",
       "4           [beet, gnocchi, steak, brown, butter, sauc]   \n",
       "...                                                 ...   \n",
       "4300                                  [yakitori, glaze]   \n",
       "4301  [pan, sear, honey, glaze, salmon, collard, green]   \n",
       "4302              [white, chocol, cheesecak, raspberri]   \n",
       "4303                  [fish, pie, fresh, smoke, salmon]   \n",
       "4304              [mushroom, bacon, pull, apart, bread]   \n",
       "\n",
       "                                            summarylema  \\\n",
       "0     [orang, fig, teacak, caramel, glaze, vegetaria...   \n",
       "1     [poach, egg, bed, fri, mushroom, countri, whit...   \n",
       "2     [26, cent, per, serv, recip, cover, 3, daili, ...   \n",
       "3     [pork, chop, honey, mustard, appl, might, main...   \n",
       "4     [recip, beet, gnocchi, steak, brown, butter, s...   \n",
       "...                                                 ...   \n",
       "4300  [yakitori, glaze, might, japanes, recip, searc...   \n",
       "4301  [pan, sear, honey, glaze, salmon, collard, gre...   \n",
       "4302  [recip, white, chocol, cheesecak, raspberri, m...   \n",
       "4303  [recip, make, 2, serv, 710, calori, 47g, prote...   \n",
       "4304  [recip, mushroom, bacon, pull, apart, bread, m...   \n",
       "\n",
       "                                       instructionslema  \\\n",
       "0     [need, 9, springform, pan, cake, pan, least, 2...   \n",
       "1     [fri, pan, heat, oil, add, mushroom, saut, 5, ...   \n",
       "2     [preheat, oven, 170c, blend, pandan, leav, wat...   \n",
       "3     [pre, heat, oven, 200c, 400f, line, roast, tin...   \n",
       "4     [cook, beet, heat, oven, 400, degre, wash, bee...   \n",
       "...                                                 ...   \n",
       "4300  [combin, ingredi, small, saucepan, bring, boil...   \n",
       "4301  [instruct, collard, green, use, non, stick, pa...   \n",
       "4302  [make, crumb, crust, small, bowl, combin, grah...   \n",
       "4303  [peel, potato, cut, chunk, cook, boil, salt, w...   \n",
       "4304  [lay, yeast, roll, counter, becom, soft, compl...   \n",
       "\n",
       "                                        ingredientslema  \\\n",
       "0     [ap, flour, bake, powder, cardamom, egg, fresh...   \n",
       "1     [bread, butter, egg, egg, mushroom, oil, salt,...   \n",
       "2     [purpos, flour, bay, leav, coconut, milk, corn...   \n",
       "3     [appl, dijon, mustard, garlic, clove, honey, j...   \n",
       "4     [gnocchi, beet, oliv, oil, p, goat, chees, ric...   \n",
       "...                                                 ...   \n",
       "4300  [butter, egg, yolk, flour, orang, zest, poppi,...   \n",
       "4301  [unbak, pie, crust, shred, cheddar, chees, jac...   \n",
       "4302  [egg, yolk, grand, marnier, light, brown, suga...   \n",
       "4303  [cashew, cumin, eggplant, flour, garam, masala...   \n",
       "4304  [puff, pastri, brie, dri, fig, appl, juic, sug...   \n",
       "\n",
       "                                   ingredient typeslema  \\\n",
       "0     [beverag, milk, egg, dairi, spice, season, bak...   \n",
       "1     [beverag, milk, egg, dairi, spice, season, oil...   \n",
       "2     [ethnic, food, produc, spice, season, beverag,...   \n",
       "3     [meat, spice, season, condiment, oil, vinegar,...   \n",
       "4     [produc, spice, season, meat, spice, season, m...   \n",
       "...                                                 ...   \n",
       "4300  [milk, egg, dairi, spice, season, bake, spice,...   \n",
       "4301  [milk, egg, dairi, meat, spice, season, bake, ...   \n",
       "4302  [beverag, milk, egg, dairi, alcohol, beverag, ...   \n",
       "4303  [beverag, spice, season, can, jar, nut, savori...   \n",
       "4304  [beverag, bake, dri, fruit, produc, chees, pro...   \n",
       "\n",
       "                                           dietslema  \n",
       "0                           [lacto, ovo, vegetarian]  \n",
       "1                           [lacto, ovo, vegetarian]  \n",
       "2              [dairi, free, lacto, ovo, vegetarian]  \n",
       "3     [gluten, free, dairi, free, paleolith, primal]  \n",
       "4                                                 []  \n",
       "...                                              ...  \n",
       "4300                        [lacto, ovo, vegetarian]  \n",
       "4301                                              []  \n",
       "4302          [gluten, free, lacto, ovo, vegetarian]  \n",
       "4303    [dairi, free, lacto, ovo, vegetarian, vegan]  \n",
       "4304                        [lacto, ovo, vegetarian]  \n",
       "\n",
       "[4305 rows x 16 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "25fe4fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__ignoreds',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__numpys',\n",
       " '__recursive_saveloads',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__scipys',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_corpus_sanity',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_epoch',\n",
       " '_do_train_job',\n",
       " '_get_next_alpha',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_scan_vocab',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_train_epoch_corpusfile',\n",
       " '_worker_loop',\n",
       " '_worker_loop_corpusfile',\n",
       " 'add_lifecycle_event',\n",
       " 'add_null_word',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'cbow_mean',\n",
       " 'comment',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'corpus_total_words',\n",
       " 'create_binary_tree',\n",
       " 'cum_table',\n",
       " 'effective_min_count',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'get_latest_training_loss',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'init_weights',\n",
       " 'layer1_size',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'make_cum_table',\n",
       " 'max_final_vocab',\n",
       " 'max_vocab_size',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'negative',\n",
       " 'ns_exponent',\n",
       " 'null_word',\n",
       " 'predict_output_word',\n",
       " 'prepare_vocab',\n",
       " 'prepare_weights',\n",
       " 'random',\n",
       " 'raw_vocab',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'scan_vocab',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'seeded_vector',\n",
       " 'sg',\n",
       " 'shrink_windows',\n",
       " 'sorted_vocab',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'update_weights',\n",
       " 'vector_size',\n",
       " 'window',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dir(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21bd72",
   "metadata": {},
   "source": [
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/ old version , for modifications : https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#3-index2word-and-index2entity-attribute-is-now-index_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd92645",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5e955de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone -b master https://github.com/charles9n/bert-sklearn\n",
    "# !cd bert-sklearn; pip install .\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c41e77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import load_model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05ce3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(t['titlelema'], tex['healthScore'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e2e09b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1627                                [dolsot, bibimbap]\n",
       " 258              [crockpot, spaghetti, pesto, meatbal]\n",
       " 3280                               [autumn, cheesecak]\n",
       " 386                              [almond, joy, cupcak]\n",
       " 847     [spaghetti, squash, tomato, basil, meat, sauc]\n",
       "                              ...                      \n",
       " 3444                    [chocol, chip, protein, cooki]\n",
       " 466                  [ham, mushroom, sauerkraut, soup]\n",
       " 3092                      [dri, prawn, yee, mee, soup]\n",
       " 3772                                    [bbq, chicken]\n",
       " 860                           [homemad, anim, cracker]\n",
       " Name: titlelema, Length: 3013, dtype: object,\n",
       " 1627    67\n",
       " 258      8\n",
       " 3280     1\n",
       " 386      1\n",
       " 847     65\n",
       "         ..\n",
       " 3444     1\n",
       " 466     16\n",
       " 3092     5\n",
       " 3772     8\n",
       " 860      2\n",
       " Name: healthScore, Length: 3013, dtype: int32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "deed7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 618502.51B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440473133/440473133 [00:39<00:00, 11272306.70B/s]\n",
      "100%|██████████| 433/433 [00:00<00:00, 108523.07B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 2712, validation data size: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:487: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Training  :   0%|          | 0/85 [00:00<?, ?it/s]C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\bert_sklearn\\model\\pytorch_pretrained\\optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1055.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "Training  : 100%|██████████| 85/85 [1:26:32<00:00, 61.09s/it, loss=4.04]  \n",
      "Validating: 100%|██████████| 38/38 [02:52<00:00,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 4.0422, Val loss: 3.8300, Val accy: 8.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [53:23<00:00, 37.69s/it, loss=3.7]  \n",
      "Validating: 100%|██████████| 38/38 [02:31<00:00,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 3.7036, Val loss: 3.7100, Val accy: 10.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [1:09:31<00:00, 49.08s/it, loss=3.56] \n",
      "Validating: 100%|██████████| 38/38 [02:38<00:00,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 3.5639, Val loss: 3.6729, Val accy: 9.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-74f732a83c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# loss, accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertClassifier() \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test, y_test) # loss, accuracy\n",
    "score = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4c61d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./mymodeltitlehealth.bin...\n",
      "Defaulting to linear classifier/regressor\n",
      "Building sklearn text classifier...\n"
     ]
    }
   ],
   "source": [
    "savefile='./mymodeltitlehealth.bin'\n",
    "model.save(savefile)\n",
    "new_model = load_model(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ed50652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 162/162 [10:22<00:00,  3.84s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_eval)\n",
    "# model.score(X_eval, y_eval) # loss, accuracy\n",
    "score = f1_score(y_eval, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e172a15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007650121001169413"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8635cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(t['instructionslema'], tex['servings'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0a5b6bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 2712, validation data size: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:487: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Training  : 100%|██████████| 85/85 [52:39<00:00, 37.17s/it, loss=2.76] \n",
      "Validating: 100%|██████████| 38/38 [02:34<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 2.7601, Val loss: 2.4864, Val accy: 27.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [42:10<00:00, 29.77s/it, loss=2.46] \n",
      "Validating: 100%|██████████| 38/38 [02:16<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 2.4627, Val loss: 2.4690, Val accy: 27.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [50:16<00:00, 35.48s/it, loss=2.45] \n",
      "Validating: 100%|██████████| 38/38 [02:13<00:00,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 2.4488, Val loss: 2.4676, Val accy: 27.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-74f732a83c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# loss, accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertClassifier() \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test, y_test) # loss, accuracy\n",
    "score = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5c3cfae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./mymodelinstructionsservings.bin...\n",
      "Defaulting to linear classifier/regressor\n",
      "Building sklearn text classifier...\n"
     ]
    }
   ],
   "source": [
    "savefile='./mymodelinstructionsservings.bin'\n",
    "model.save(savefile)\n",
    "new_model = load_model(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "06f6dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 162/162 [08:43<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_eval)\n",
    "# model.score(X_eval, y_eval) # loss, accuracy\n",
    "score = f1_score(y_eval, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1c84f148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010931009712982916"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "19d6a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(t['instructionslema'], tex['readyInMinutes'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3fd8ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 2712, validation data size: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:487: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Training  : 100%|██████████| 85/85 [1:18:07<00:00, 55.15s/it, loss=2.19]   \n",
      "Validating: 100%|██████████| 38/38 [02:41<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 2.1877, Val loss: 1.7508, Val accy: 70.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [53:33<00:00, 37.80s/it, loss=1.58] \n",
      "Validating: 100%|██████████| 38/38 [02:32<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.5831, Val loss: 1.6915, Val accy: 70.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [54:18<00:00, 38.34s/it, loss=1.56] \n",
      "Validating: 100%|██████████| 38/38 [02:26<00:00,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.5598, Val loss: 1.6818, Val accy: 70.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(do_lower_case=True,\n",
       "               label_list=array([   2,    3,    4,    5,    6,    7,    8,   10,   11,   12,   13,\n",
       "         14,   15,   16,   17,   18,   20,   22,   23,   24,   25,   27,\n",
       "         28,   29,   30,   31,   32,   33,   34,   35,   36,   37,   38,\n",
       "         40,   41,   44,   45,   46,   47,   50,   55,   57,   60,   64,\n",
       "         65,   70,   74,   75,   77,   80,   82,   84,   85,   90,   95,\n",
       "        100,  105,  110,  115,  120,  125,  130,  135,  140,  150,  160,\n",
       "        165,  170,  180,  185,  200,  205,  210,  215,  220,  230,  240,\n",
       "        250,  255,  260,  270,  275,  300,  310,  315,  350,  360,  370,\n",
       "        380,  390,  400,  420,  425,  450,  465,  485,  490,  495,  500,\n",
       "        520,  540,  615,  660,  845,  910,  980, 1440, 1460, 1500, 3595],\n",
       "      dtype=int64))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5c21fa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./mymodelinstructionsinminutes.bin...\n",
      "Defaulting to linear classifier/regressor\n",
      "Building sklearn text classifier...\n"
     ]
    }
   ],
   "source": [
    "savefile='./mymodelinstructionsinminutes.bin'\n",
    "model.save(savefile)\n",
    "new_model = load_model(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2e5f20a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 162/162 [08:33<00:00,  3.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011545806321925724"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_eval)\n",
    "f1_score(y_eval, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0185d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(t['ingredientslema'], tex['readyInMinutes'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bb75d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 2712, validation data size: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:487: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Training  : 100%|██████████| 85/85 [2:33:30<00:00, 108.36s/it, loss=2.22]    \n",
      "Validating: 100%|██████████| 38/38 [02:36<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 2.2164, Val loss: 1.7440, Val accy: 70.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [12:07:59<00:00, 513.88s/it, loss=1.58]     \n",
      "Validating: 100%|██████████| 38/38 [03:02<00:00,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.5825, Val loss: 1.6984, Val accy: 70.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 85/85 [53:19<00:00, 37.64s/it, loss=1.57] \n",
      "Validating: 100%|██████████| 38/38 [02:37<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.5666, Val loss: 1.6990, Val accy: 70.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(do_lower_case=True,\n",
       "               label_list=array([   2,    3,    4,    5,    6,    7,    8,   10,   11,   12,   13,\n",
       "         14,   15,   16,   17,   18,   20,   22,   23,   24,   25,   27,\n",
       "         28,   29,   30,   31,   32,   33,   34,   35,   36,   37,   38,\n",
       "         40,   41,   44,   45,   46,   47,   50,   55,   57,   60,   64,\n",
       "         65,   70,   74,   75,   77,   80,   82,   84,   85,   90,   95,\n",
       "        100,  105,  110,  115,  120,  125,  130,  135,  140,  150,  160,\n",
       "        165,  170,  180,  185,  200,  205,  210,  215,  220,  230,  240,\n",
       "        250,  255,  260,  270,  275,  300,  310,  315,  350,  360,  370,\n",
       "        380,  390,  400,  420,  425,  450,  465,  485,  490,  495,  500,\n",
       "        520,  540,  615,  660,  845,  910,  980, 1440, 1460, 1500, 3595],\n",
       "      dtype=int64))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f79c6da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./mymodelingredientsinminutes.bin...\n",
      "Defaulting to linear classifier/regressor\n",
      "Building sklearn text classifier...\n"
     ]
    }
   ],
   "source": [
    "savefile='./mymodelingredientsinminutes.bin'\n",
    "model.save(savefile)\n",
    "new_model = load_model(savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9d8dc22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 162/162 [09:49<00:00,  3.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011545806321925724"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_eval)\n",
    "f1_score(y_eval, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0d29569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:487: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Predicting: 100%|██████████| 162/162 [10:07<00:00,  3.75s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8576fb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7330921"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cc244be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e9a949db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.0191920e-04, 2.7609745e-04, 5.5767712e-04, 6.4984593e-03,\n",
       "       5.1068945e-04, 3.4127527e-04, 5.5356970e-04, 1.6071022e-02,\n",
       "       7.2688347e-04, 3.4052361e-04, 5.7525019e-04, 4.6103194e-04,\n",
       "       1.5992651e-02, 7.4952183e-04, 4.2284644e-04, 1.1205886e-03,\n",
       "       1.3612257e-02, 9.1865566e-04, 5.6325755e-04, 2.7149479e-04,\n",
       "       1.5442854e-02, 7.8833033e-04, 2.4012367e-03, 5.7630584e-04,\n",
       "       3.8512114e-02, 5.2325480e-04, 5.5834127e-04, 3.9455103e-04,\n",
       "       3.4985199e-04, 1.2640856e-02, 5.2199204e-04, 4.9945037e-04,\n",
       "       5.5524922e-04, 1.4081030e-02, 9.0136984e-04, 4.8345231e-04,\n",
       "       7.2309226e-01, 3.6885243e-04, 4.9275602e-04, 8.4094619e-03,\n",
       "       7.9541169e-03, 4.0869438e-04, 2.2682641e-02, 5.3224887e-04,\n",
       "       4.5949784e-03, 5.0346078e-03, 5.1630248e-04, 1.3578891e-02,\n",
       "       7.5623940e-04, 3.6186709e-03, 5.5201375e-04, 6.0606765e-04,\n",
       "       6.8384287e-04, 7.4105039e-03, 1.3131786e-03, 1.0172301e-03,\n",
       "       1.5008138e-03, 1.0285012e-03, 4.4902868e-04, 2.5206443e-03,\n",
       "       1.0672779e-03, 1.2515378e-03, 6.1195018e-04, 5.9949391e-04,\n",
       "       2.1114817e-03, 1.8765603e-04, 1.4705128e-03, 3.7729790e-04,\n",
       "       4.8824227e-03, 5.0126814e-04, 7.8854273e-04, 7.0342631e-04,\n",
       "       6.4087746e-04, 5.0363265e-04, 4.6508430e-04, 1.5599217e-04,\n",
       "       2.1529207e-03, 3.3764605e-04, 1.4791262e-03, 2.1434466e-04,\n",
       "       6.7467545e-04, 6.2314235e-04, 9.8879437e-04, 3.6659752e-04,\n",
       "       8.8846695e-04, 9.7235065e-04, 7.6600030e-04, 1.0886161e-03,\n",
       "       4.7040035e-04, 5.6995056e-04, 6.8156736e-04, 4.3569712e-04,\n",
       "       3.5720583e-04, 5.4670818e-04, 4.9415795e-04, 7.5315248e-04,\n",
       "       5.8392249e-04, 8.6874189e-04, 1.5790465e-03, 6.5784820e-04,\n",
       "       3.9294967e-04, 7.4853247e-04, 4.9936940e-04, 6.0397573e-04,\n",
       "       3.4836028e-04, 4.0804557e-04, 6.6195265e-04, 5.2139803e-04,\n",
       "       5.8888458e-04, 7.3847955e-04], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "88f9120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = []\n",
    "for i in y_pred : \n",
    "    y_prob.append(max(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a81bdc28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.721892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.704161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.718619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.722842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.725816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.733092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1292.000000\n",
       "mean      0.721892\n",
       "std       0.005796\n",
       "min       0.704161\n",
       "25%       0.718619\n",
       "50%       0.722842\n",
       "75%       0.725816\n",
       "max       0.733092"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_describe = pd.DataFrame(y_prob)\n",
    "df_describe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73fe02",
   "metadata": {},
   "source": [
    "The mean value of the higher probability prediction it's around 70% , quite high considering the f-score it's really low, there is not predicting the correct value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
